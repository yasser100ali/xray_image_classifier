{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9328577,"sourceType":"datasetVersion","datasetId":5651871}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nGoal of this notebook is to take our x-ray png files and build a convolutional neural network to predict which images are part of 'findings' and which are part of 'no-findings'\n\nProcedure and Outline\n\nLoading the data\n1. Use ImageDataGenerator to create augmentations of the data \n2. Split into training and validation subset\n\nTraining The Model\n1. Load the pretrained models\n2. Set trainable to False\n3. Create a custom layer on top of this model -> Convolutional Layer, MaxPooling2D, Dense(128), Dense(1). \n4. * Experiment with dropout to see if it helps\n5. Compile the model -> Set the learning rate (tf.keras.?.adam), loss='binary_crossentropy' since it is a binary classification problem, metric=['accuracy'] (or MatthewCorrelationCoefficient see step 1 of Testing)\n6. Create history = model.fit(train=(X_train, y_train), validation=(X_val, y_val), epochs=5, verbose=1, batch_size=32)\n\nTesting\n1. Create a function to get the metric (using Matthew Correlation Coefficient) -> may have to do this prior to compiling the model and set this function as the metric. Look more into this, test both.\n2. Create an array, y_test = model.predict(X_test)\n3. Submit and see score\n\nAssessment\nTry to find weaknesses and see where you can Improve\n\"\"\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-05T17:10:29.536482Z","iopub.execute_input":"2024-09-05T17:10:29.536950Z","iopub.status.idle":"2024-09-05T17:10:29.550463Z","shell.execute_reply.started":"2024-09-05T17:10:29.536905Z","shell.execute_reply":"2024-09-05T17:10:29.547915Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"\"\\nGoal of this notebook is to take our x-ray png files and build a convolutional neural network to predict which images are part of 'findings' and which are part of 'no-findings'\\n\\nProcedure and Outline\\n\\nImage Dataset\\n1. Load the image dataset\\n2. Convert the dataset into a numpy array\\n3. Define this array as X\\n\\nLabels\\n1. Load the label dataset\\n2. Take the column 'Finding' and convert that column alone into a numpy array. Since the column is already in order, there is an ordered bijective relationship between this column and the image dataset\\n3. Define this column as Y\\n\\n Preprocessing\\n1. Split X into X_train, X_val. X_train is first 8,000 images, and X_val is last 2,000\\n2. Repeat for Y\\n3. * Perform augmentation on the dataset, shift up/down/right/left, rotate, zoom in, change brightnes, flip on horizontal access. Do this step after you do first run through and see what difference it makes\\n\\nTraining The Model\\n1. Load the pretrained res-net50 model\\n2. Set trainable to False\\n3. Create a custom layer on top of this model -> Convolutional Layer, MaxPooling2D, Dense(128), Dense(1). \\n4. * Experiment with dropout to see if it helps\\n5. Compile the model -> Set the learning rate (tf.keras.?.adam), loss='binary_crossentropy' since it is a binary classification problem, metric=['accuracy'] (or MatthewCorrelationCoefficient see step 1 of Testing)\\n6. Create history = model.fit(train=(X_train, y_train), validation=(X_val, y_val), epochs=5, verbose=1, batch_size=32)\\n\\nTesting\\n1. Create a function to get the metric (using Matthew Correlation Coefficient) -> may have to do this prior to compiling the model and set this function as the metric. Look more into this, test both.\\n2. Create an array, y_test = model.predict(X_test)\\n3. Submit and see score\\n\\nAssessment\\nTry to find weaknesses and see where you can Improve\\n\""},"metadata":{}}]},{"cell_type":"code","source":"# import required libraries\nimport numpy as np\nimport pandas as pd\nimport os\n\n# image processing\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# machine learning libraries\nimport tensorflow as tf\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nfrom tensorflow.keras.applications import DenseNet169\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input, BatchNormalization, Concatenate, Flatten\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T23:14:58.803125Z","iopub.execute_input":"2024-09-05T23:14:58.803524Z","iopub.status.idle":"2024-09-05T23:14:58.809792Z","shell.execute_reply.started":"2024-09-05T23:14:58.803486Z","shell.execute_reply":"2024-09-05T23:14:58.808936Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_file_path = '/kaggle/input/dataset/Train_PNG/Train_PNG'\n\ndatagen = ImageDataGenerator(\n    rescale = 1.0/255.00,\n    rotation_range = 10,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    zoom_range = 0.1,\n    validation_split = 0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory = train_file_path,\n    target_size = (512, 512),\n    color_mode = 'rgb',\n    class_mode = 'binary', \n    batch_size = 32,\n    shuffle = False,\n    subset = 'training'\n)\n\nvalidation_generator = datagen.flow_from_directory(\n    directory = train_file_path,\n    target_size = (512, 512),\n    color_mode = 'rgb',\n    class_mode = 'binary',\n    batch_size = 32,\n    shuffle = False,\n    subset = 'validation'\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T21:42:24.561327Z","iopub.execute_input":"2024-09-05T21:42:24.562331Z","iopub.status.idle":"2024-09-05T21:42:29.207136Z","shell.execute_reply.started":"2024-09-05T21:42:24.562283Z","shell.execute_reply":"2024-09-05T21:42:29.206365Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found 8001 images belonging to 2 classes.\nFound 1999 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"input_layer = Input(shape=(512, 512, 3))\n\nmobilenet_base = MobileNetV2(weights='imagenet', input_shape=(512, 512, 3), include_top=False)\ndensenet_base = DenseNet169(weights='imagenet', input_shape=(512, 512, 3), include_top=False)\n\n# set the layers not trainable to preserve weights of pretrained model\nfor layer in mobilenet_base.layers:\n    layer.trainable=False\nfor layer in densenet_base.layers:\n    layer.trainable=False\n\nmodel_mobilenet = mobilenet_base(input_layer) \nmodel_mobilenet = GlobalAveragePooling2D()(model_mobilenet)\noutput_mobilenet = Flatten()(model_mobilenet)\n\nmodel_densenet = densenet_base(input_layer) \nmodel_densenet = GlobalAveragePooling2D()(model_densenet)\noutput_densenet = Flatten()(model_densenet)\n\nmerged = Concatenate()([output_mobilenet, output_densenet])\n\nx = BatchNormalization()(merged)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(inputs=input_layer, outputs=x)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T23:15:28.464183Z","iopub.execute_input":"2024-09-05T23:15:28.464608Z","iopub.status.idle":"2024-09-05T23:15:33.417441Z","shell.execute_reply.started":"2024-09-05T23:15:28.464567Z","shell.execute_reply":"2024-09-05T23:15:33.416466Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1471134529.py:3: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n  mobilenet_base = MobileNetV2(weights='imagenet', input_shape=(512, 512, 3), include_top=False)\n","output_type":"stream"}]},{"cell_type":"code","source":"for layer in base_model.layers[-10:]:\n    layer.trainable = True\n\nmodel.compile(\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nearly_stopping = EarlyStopping(patience=3, restore_best_weights=True)\n\nlr_reducer = ReduceLROnPlateau(\n    monitor='val_loss',\n    patience=3,\n    verbose=1,\n    factor=0.5,\n    min_lr=0.0001\n)\n\ncheckpoint_callback = ModelCheckpoint(\n    filepath='model_checkpoint.weights.h5',\n    save_weights_only=True,\n    save_best_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T23:15:38.701684Z","iopub.execute_input":"2024-09-05T23:15:38.702070Z","iopub.status.idle":"2024-09-05T23:15:38.716741Z","shell.execute_reply.started":"2024-09-05T23:15:38.702035Z","shell.execute_reply":"2024-09-05T23:15:38.715827Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    epochs=5,\n    batch_size=32,\n    validation_data=validation_generator,\n    verbose=1,\n    callbacks=[checkpoint_callback, lr_reducer, early_stopping] # run again to see effects of lr_reducer and early_stopping\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T23:15:43.815250Z","iopub.execute_input":"2024-09-05T23:15:43.815670Z","iopub.status.idle":"2024-09-06T00:04:41.394977Z","shell.execute_reply.started":"2024-09-05T23:15:43.815632Z","shell.execute_reply":"2024-09-06T00:04:41.394108Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5665 - loss: 0.7983","output_type":"stream"},{"name":"stderr","text":"2024-09-05 23:27:35.649208: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng3{k11=2} for conv (f32[15,128,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[15,256,128,128]{3,2,1,0}, f32[128,256,1,1]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n2024-09-05 23:27:35.769672: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.120573004s\nTrying algorithm eng3{k11=2} for conv (f32[15,128,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[15,256,128,128]{3,2,1,0}, f32[128,256,1,1]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_accuracy improved from -inf to 0.71236, saving model to model_checkpoint.weights.h5\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 3s/step - accuracy: 0.5667 - loss: 0.7980 - val_accuracy: 0.7124 - val_loss: 0.5800 - learning_rate: 1.0000e-05\nEpoch 2/5\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6406 - loss: 0.6958\nEpoch 2: val_accuracy improved from 0.71236 to 0.73037, saving model to model_checkpoint.weights.h5\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m553s\u001b[0m 2s/step - accuracy: 0.6408 - loss: 0.6955 - val_accuracy: 0.7304 - val_loss: 0.5191 - learning_rate: 1.0000e-05\nEpoch 3/5\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6920 - loss: 0.6146\nEpoch 3: val_accuracy improved from 0.73037 to 0.76488, saving model to model_checkpoint.weights.h5\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 2s/step - accuracy: 0.6921 - loss: 0.6144 - val_accuracy: 0.7649 - val_loss: 0.4822 - learning_rate: 1.0000e-05\nEpoch 4/5\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7546 - loss: 0.5065\nEpoch 4: val_accuracy improved from 0.76488 to 0.79790, saving model to model_checkpoint.weights.h5\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 2s/step - accuracy: 0.7546 - loss: 0.5066 - val_accuracy: 0.7979 - val_loss: 0.4487 - learning_rate: 1.0000e-05\nEpoch 5/5\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7806 - loss: 0.4657\nEpoch 5: val_accuracy improved from 0.79790 to 0.80240, saving model to model_checkpoint.weights.h5\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 2s/step - accuracy: 0.7806 - loss: 0.4658 - val_accuracy: 0.8024 - val_loss: 0.4335 - learning_rate: 1.0000e-05\n","output_type":"stream"}]},{"cell_type":"code","source":"test_file_path = '/kaggle/input/dataset/Test_PNG 2/Test_PNG'\ntest_datagen = ImageDataGenerator(rescale=1.0/255.0)\ntest_generator = test_datagen.flow_from_directory(\n    directory=test_file_path,\n    target_size=(512, 512),\n    color_mode='rgb',\n    class_mode=None,\n    batch_size=32,\n    shuffle=False\n)\npredictions = model.predict(test_generator)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T00:18:54.442010Z","iopub.execute_input":"2024-09-06T00:18:54.442377Z","iopub.status.idle":"2024-09-06T00:19:58.478872Z","shell.execute_reply.started":"2024-09-06T00:18:54.442344Z","shell.execute_reply":"2024-09-06T00:19:58.477874Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Found 2000 images belonging to 1 classes.\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step \n","output_type":"stream"}]},{"cell_type":"code","source":"# could play around with this and see if it makes much difference in score\ny_pred = np.where(predictions>0.32, 1, 0)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T00:39:38.866441Z","iopub.execute_input":"2024-09-06T00:39:38.867179Z","iopub.status.idle":"2024-09-06T00:39:38.871514Z","shell.execute_reply.started":"2024-09-06T00:39:38.867140Z","shell.execute_reply":"2024-09-06T00:39:38.870673Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"count0 = 0\ncount1 = 0\nfor i in range(len(y_pred)):\n    if y_pred[i] == 0:\n        count0 +=1\n    else:\n        count1 += 1\nprint(count0 / len(y_pred))\nprint(count1 / len(y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-09-06T00:39:39.372001Z","iopub.execute_input":"2024-09-06T00:39:39.372347Z","iopub.status.idle":"2024-09-06T00:39:39.383739Z","shell.execute_reply.started":"2024-09-06T00:39:39.372312Z","shell.execute_reply":"2024-09-06T00:39:39.382675Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"0.7075\n0.2925\n","output_type":"stream"}]},{"cell_type":"code","source":"from datetime import datetime\n\ny_submission = pd.read_csv('/kaggle/input/dataset/data (4).csv')\ny_submission = y_submission[-2000:].reset_index(drop=True)\ny_submission.loc[0:1999, 'Finding'] = y_pred\ny_submission['id'] = y_submission['id'].apply(lambda x: str(x).zfill(5))\ny_submission.rename(columns={'Finding': 'Outcome'}, inplace=True)\ny_submission['Outcome'] = y_submission['Outcome'].astype(int)\ny_submission\n\ny_submission.to_csv(f\"submit_{datetime.today().strftime('%Y-%m-%d_%H%M%S')}.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T01:15:06.783772Z","iopub.execute_input":"2024-09-06T01:15:06.784159Z","iopub.status.idle":"2024-09-06T01:15:06.803428Z","shell.execute_reply.started":"2024-09-06T01:15:06.784123Z","shell.execute_reply":"2024-09-06T01:15:06.802623Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"import zipfile\n\ny_submission.to_csv('submission.csv', index=False)\nwith zipfile.ZipFile('submission.zip', 'w') as zipf:\n    zipf.write('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-06T00:51:08.684999Z","iopub.execute_input":"2024-09-06T00:51:08.685830Z","iopub.status.idle":"2024-09-06T00:51:08.696671Z","shell.execute_reply.started":"2024-09-06T00:51:08.685790Z","shell.execute_reply":"2024-09-06T00:51:08.695809Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}